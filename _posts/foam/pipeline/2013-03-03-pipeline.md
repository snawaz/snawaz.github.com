---
layout: library
title: Overview of Pipeline
name: Pipeline
showdoc: true
description: A LINQ-like library with few differences. It supports composition in a way that LINQ does not.
permalink: /foam/pipeline.html
---

Pipeline is an incubation effort to mimic LINQ<sup>1</sup> to a great extent, with few differences such as Pipeline supports composition in a way that LINQ doesn't, as a result of which you can *reuse* a query written in Pipeline for as many data source as you want. In LINQ, that is not possible.

Other differences arise from their semantics and the naming convention which is explained in the next section. Pipeline mixes quite well with [Expression][expression] library. In fact, they're so intertwined together that they are put in the same namespace called `foam::composition`.

<sup>
1. <i>Note that when I say LINQ, I mean <a href="http://msdn.microsoft.com/en-us/library/bb397919.aspx">LINQ-to-Objects</a>. Pipeline has nothing to do with <a href="http://msdn.microsoft.com/en-us/library/bb386976.aspx">LINQ-to-SQL</a> and <a href="http://msdn.microsoft.com/en-us/library/bb387098.aspx">LINQ-to-XML</a></i>.
</sup>

###LINQ vis-a-vis Pipeline

Pipeline believes in calling a spade a spade. For example, Pipeline calls a filter a [*filter*][filter], whereas LINQ calls 
a filter a [*Where*][where] due to reification of 
the idea of filtering. Likewise, Pipeline calls a transform a [*transform*][transform] instead of [*Select*][select] and [*accumulate*][accumulate] instead of 
[*Aggregate*][aggregate].

####Composability

Consider this LINQ query,

{% highlight csharp %}
var names = participants                           //bind to source
           .Where(p => p.Age >= 13 && p.Age <= 19) //filtering
           .Select(p => p.Name)                    //transformation

//Or using query-operators
var names = from p in participants                //bind to source
            where p => p.Age >= 13 && p.Age <= 19 //filtering
            select p.Name                         //transformation
{% endhighlight %}

In this snippet, the query is bound to *persons*. If you want to do the same with another collection of person, then you've to write the whole query again. Pipeline avoids this problem by allowing you to compose different pieces of sub-query to form your query, **without** requiring you to bind the resulting query to 
a collection of entities. This enables *reuse*, because once you've your unbounded query, you can bind it to a collection of your choice later on. 

The equivalent of above LINQ query in Pipeline would be this,

{% highlight cpp %}
auto names =  from (participants)                                       //bind to source
            | filter([](person p) { return p.age >= 13 && p.age <=19 }) //filtering
            | transform([](person p) { return p.name; } );              //transformation

{% endhighlight %}

Now after removing the *source* from the above query (i.e the *from* clause), what we're left with is, *reusuable* query, as it is **not** bound to any data source:

{% highlight cpp %}
auto query = filter([](person p) { return p.age >= 13 && p.age <=19 }) //filtering
           | transform([](person p) { return p.name; });               //transformation
{% endhighlight %}

As we can see, there is no *participants* collection which the query is bounded to. So once we've this we can reuse it as:

{% highlight cpp %}
auto names1 = from(participants) | query; //bind to a collection, then execute the query.
auto names2 = from(students) | query;     //bind to a different collection and execute.
{% endhighlight %}

Pipeline is very flexible, so it comes with an alternative syntax : we can execute *query* as if it is a function,

{% highlight cpp %}
auto names1 = query(participants);  //execute for participants
auto names2 = query(students);      //execute for students
{% endhighlight %}

That is a *powerful* feature, because you can pass around *query* to functions which accept *functor* 
and execute it passing different collections,

{% highlight cpp %}
template<typename Functor>
void f(Functor && selectNames)
{
   auto participantNames = selectNames(get_participants());  
   auto studentNames     = selectNames(get_students());      
   //...
}

f(query); //pass the unbounded query!

//we can do these too!
auto nameSelector = transform([](person p) { return p.name; });
auto teenFilter = filter([](person p) { return p.age >= 13 && p.age <=19 });

f(nameSelector);               //select name of ALL persons (no filter)
f(teenFilter | nameSelector ); //select name of teenagers only (same as query!)
{% endhighlight %}

The last example shows we can apply filter later on also. In general, we can compose and apply different kinds of filter, transform, and other pipes on the fly!

####Semantics

There are many semantical differences between LINQ and Pipeline, the most interesting being between LINQ's Range() and Pipeline's range(). Consider generating the following sequence of natural numbers:

    [5, 6, 7, 8, 9, 10, 11, 12]

In LINQ, you would do this:

{% highlight csharp %}
var numbers = Enumerable.Range(5,8); //gives [5, 6, 7, ...12]
{% endhighlight %}

What is the second argument? Why is it 8? Well, while the first argument is the first value in the sequence, the second argument is the *"number of sequential integers to generate"* [as per the documentation][linq.Range]. The sequence has 8 numbers, therefore the second argument is 8. It is pretty much straightforward. So far so good.

Now considering generating this sequence (which is *reverse* of the previous one):

    [12, 11, 10, 9, 8, 7, 6, 5]

LINQ has problem with it. It cannot *generate* it! Instead you have to generate the sequence in increasing order, then reverse it:

{% highlight csharp %}
var numbers = Enumerable.Range(5,8).Reverse(); //gives [12, 11, 10, ...5]
{% endhighlight %}

That is most certainly not efficient. If it has to be in decreasing order, why does it not generate in that order to begin with?

[Pipeline's range][range] solves this problem by *interpreting* the second argument differently. The second argument is **not** the *"number of sequential integers 
to generate"* anymore. It is rather *past-the-last* element to generate. That is,

 - If the number to generate is 12 in an *increasing* sequence, then the second argument is 13.
 - If the number to generate is 5 in a *decreasing* sequence, then the second argument is 4.

So in Pipeline, the code would be this:

{% highlight cpp %}
auto increasingNumbers = range(5,13); //gives [5, 6, 7, ...12]
auto decreasingNumbers = range(12,4); //gives [12, 11, 10, ...5]
{% endhighlight %}

which is quite elegant and concise.

Even mathematically speaking, the range `[5,6,7,...12]` would be represented by the following conventions:

{% highlight cpp %}
a)  [5,12] i.e 5 <= i <= 12
b)  [5,13) i.e 5 <= i < 13
c)  (4,13) i.e 4 < i < 13
d)  (4,12] i.e 4 < i <= 12
{% endhighlight %}

While all are valid and widely-used conventions, Pipeline has adopted the second convention i.e `[5,13)`, and there is a *reason* to prefer this over the others! Edsger W. Dijkstra has given an excellent argument as to why the second convention is to be preferred, in this tiny article:

 - [Why numbering should start at zero][dijkstra]

which is a must-read.

Note that LINQ doesn't follow any of these conventions.

[dijkstra]:http://www.cs.utexas.edu/users/EWD/transcriptions/EWD08xx/EWD831.html

[where]:http://msdn.microsoft.com/en-us/library/bb534803.aspx
[select]:http://msdn.microsoft.com/en-us/library/system.linq.enumerable.select.aspx
[aggregate]:http://msdn.microsoft.com/en-us/library/system.linq.enumerable.aggregate.aspx
[linq.Range]:http://msdn.microsoft.com/en-us/library/system.linq.enumerable.range.aspx

[expression]: /foam/expression.html
[filter]: /foam/pipeline/filter.html
[transform]: /foam/pipeline/transform.html
[accumulate]: /foam/pipeline/accumulate.html 
[range]:/foam/pipeline/range.html

###Deferred Execution

Like LINQ, Pipeline also supports deferred execution. It can be best understood using an example,

{% highlight cpp %}
std::vector<int> xs {23,42,89,34};
auto results = from(xs)
	      | filter([](int i) {
			  std::cout << "apply filtering on " << i << std::endl;
			  return i < 50 ;
		      })
	      | transform([](int i) { 
			  std::cout << i << " being transformed to " << (i*10) << std::endl; 
			  return i*10;
  		      });

std::cout << "BEFORE LOOP" << std::endl;
for(auto && r : results )
   std::cout << "r = " << r << std::endl;
{% endhighlight %}

Without deferred execution, the output would have been this:

{% highlight cpp %}
apply filtering on 23
apply filtering on 42
apply filtering on 89
apply filtering on 34
23 being transformed to 230
42 being transformed to 420
34 being transformed to 340
BEFORE LOOP
r = 230
r = 420
r = 340
{% endhighlight %}
  
But the **actual output** is this:

{% highlight cpp %}
BEFORE LOOP
apply filtering on 23
23 being transformed to 230
r = 230
apply filtering on 42
42 being transformed to 420
r = 420
apply filtering on 89
apply filtering on 34
34 being transformed to 340
r = 340
{% endhighlight %}

Note *"BEFORE LOOP"* which marks the beginning of the actual output. 
It shows that the pipeline is not executed before the *for* loop even though it is created before it. As soon as it enters into the loop and iterates over 
the results, the pipeline *starts* executing in a **back-and-forth** manner. No iteration means no execution, no *actual* filtering, no *actual* transformation. 
Furthermore, only as many items go through the pipeline and get processed as the iteration asked for.

###Pipeline + Expression = Elegance

Consider this code which uses lambda,

{% highlight cpp%}

std::vector<int> v {1,2,3,4,5,6,7,8,9,10};

auto evens = from(v)
           | filter ( [](int i) { return i % 2 == 0; } ); //filter even integers

auto triples = from(v)
             | filter ( [](int i) { return i % 2 == 0; } ); //filter even integers
             | transform ( [](int i) { return i *3 ; } );   //then triple them

{% endhighlight %}
    
Using Expression, the above code would become,

{% highlight cpp%}

expression<int> x; //declare a variable!

auto evens = from(v) 
           | filter(x % 2 == 0); //filter even integers

auto triples = from(v) 
             | filter(x % 2 == 0)  //filter even integers
             | transform(x * 3);   //then triple them.

{% endhighlight %}

which is quite concise and clean.

